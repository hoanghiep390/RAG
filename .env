# ============================================
# MONGODB CONFIGURATION
# ============================================
# Local MongoDB (default)
MONGODB_URI=mongodb://localhost:27017/
MONGODB_DATABASE=lightrag_db


# ============================================
# LLM PROVIDER CONFIGURATION
# ============================================
# Choose provider: openai OR groq
LLM_PROVIDER=groq

# âœ… UPDATED: New Groq models (llama-3.1-70b-versatile is DECOMMISSIONED)
# Recommended models:
# - llama-3.3-70b-versatile (BEST - newest, most capable)
# - llama-3.1-8b-instant (FASTEST - for quick testing)
# - mixtral-8x7b-32768 (GOOD - large context window)
LLM_MODEL=llama-3.3-70b-versatile

# For OpenAI (if using openai provider):
# LLM_MODEL=gpt-4o-mini


# ============================================
# API KEYS
# ============================================
# OpenAI API Key (get from: https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Groq API Key (get from: https://console.groq.com/keys) - RECOMMENDED FOR DEMO
GROQ_API_KEY=gsk_your-groq-api-key-here


# ============================================
# EMBEDDING CONFIGURATION
# ============================================
# Embedding model (default: all-MiniLM-L6-v2)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Embedding dimension (384 for all-MiniLM-L6-v2)
EMBEDDING_DIM=384


# ============================================
# PERFORMANCE TUNING (OPTIMIZED)
# ============================================
# Parallel LLM calls for entity extraction
MAX_CONCURRENT_LLM_CALLS=16

# Chunks processed per extraction batch
EXTRACTION_BATCH_SIZE=20

# Embeddings generated per batch
EMBEDDING_BATCH_SIZE=128


# ============================================
# CHUNKING CONFIGURATION
# ============================================
# Default chunk size in tokens
DEFAULT_CHUNK_SIZE=300

# Default overlap between chunks
DEFAULT_CHUNK_OVERLAP=50


# ============================================
# FAISS CONFIGURATION
# ============================================
# Use HNSW index (faster search, more memory)
USE_HNSW=true

# HNSW parameters (only used if USE_HNSW=true)
HNSW_M=32                       # Number of connections per node (16-64)
HNSW_EF_CONSTRUCTION=200        # Construction quality (100-500)
HNSW_EF_SEARCH=50              # Search quality (10-100)


# ============================================
# STORAGE CONFIGURATION
# ============================================
# Maximum file size in MB
MAX_FILE_SIZE_MB=50

# Auto rebuild FAISS when deletion ratio exceeds this
AUTO_REBUILD_THRESHOLD=0.2

# Data directory (default: backend/data)
DATA_DIR=backend/data


# ============================================
# OPTIONAL SETTINGS
# ============================================
# Enable debug logging (optional)
# DEBUG=True

# Custom port for Streamlit (optional, default 8501)
# STREAMLIT_PORT=8501

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

