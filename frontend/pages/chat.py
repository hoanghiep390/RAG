# frontend/pages/chat.py (SHARED DATA VERSION)
"""
ğŸ’¬ Chat Interface - Users share admin's data
"""
import streamlit as st
import sys
import os
import time
from datetime import datetime

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from backend.db.vector_db import VectorDatabase
from backend.db.mongo_storage import MongoStorage
from backend.db.conversation_storage import ConversationStorage
from backend.db.feedback_storage import FeedbackStorage
from backend.retrieval.hybrid_retriever import EnhancedHybridRetriever
from backend.retrieval.conversation_manager import ConversationManager
from backend.evaluation.response_evaluator import ResponseEvaluator
from backend.utils.llm_utils import call_llm_async, call_llm_stream
import asyncio


# ================= Auth Check =================
if not st.session_state.get('authenticated', False):
    st.switch_page("login.py")

user_id = st.session_state.get('user_id', 'admin_00000000')
username = st.session_state.get('username', 'User')
role = st.session_state.get('role', 'user')

#
DATA_USER_ID = 'admin_00000000'  # All users read from admin's data

# ================= Page Config =================
st.set_page_config(
    page_title="LightRAG | Chat",
    layout="wide"
)

# ================= CSS =================
st.markdown("""
<style>
    .main { background-color: #0e1117; }
    
    .header-container { 
        background: linear-gradient(90deg, #1e1e1e 0%, #2d2d2d 100%); 
        padding: 1.5rem; 
        border-radius: 10px; 
        margin-bottom: 2rem; 
        border-left: 5px solid #3b82f6; 
    }
    .header-title { 
        color: #3b82f6; 
        font-size: 2rem; 
        font-weight: 700; 
        margin: 0; 
    }
    
    .role-badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: 600;
        margin-left: 1rem;
    }
    .badge-admin { background: #dc2626; color: white; }
    .badge-user { background: #10b981; color: white; }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        margin-left: 20%;
    }
    .assistant-message {
        background: #1e1e1e;
        color: white;
        margin-right: 20%;
        border-left: 4px solid #3b82f6;
    }
    
    .context-preview {
        background: #1a1a1a;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #10b981;
        margin: 1rem 0;
        font-size: 0.9rem;
    }
    
    .stat-badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: 600;
        margin-right: 0.5rem;
    }
    .badge-chunks { background: #3b82f6; color: white; }
    .badge-entities { background: #8b5cf6; color: white; }
    .badge-time { background: #10b981; color: white; }
    
    .info-box {
        background: #1e3a8a;
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        border-left: 4px solid #3b82f6;
    }
    
    /* Feedback Styles */
    .feedback-container {
        background: #1a1a1a;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0 1rem 2rem;
        border-left: 3px solid #f59e0b;
    }
    .star-rating {
        font-size: 1.5rem;
        cursor: pointer;
        user-select: none;
    }
    .star-rating span {
        color: #4b5563;
        transition: color 0.2s;
    }
    .star-rating span:hover,
    .star-rating span.selected {
        color: #fbbf24;
    }
    .feedback-submitted {
        background: #065f46;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 6px;
        margin: 0.5rem 0;
    }
    
    /* Evaluation Styles */
    .evaluation-container {
        background: #1a1a1a;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0 1rem 2rem;
        border-left: 3px solid #8b5cf6;
    }
    .evaluation-badge {
        display: inline-block;
        padding: 0.5rem 1rem;
        border-radius: 8px;
        margin: 0.3rem;
        font-weight: 600;
        font-size: 0.9rem;
    }
    .badge-relevancy {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
        color: white;
    }
    .badge-faithfulness {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
    }
    .badge-response-time {
        background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
        color: white;
    }
    .evaluation-score {
        font-size: 1.2rem;
        font-weight: 700;
    }
    .evaluation-reason {
        background: #2d2d2d;
        padding: 0.5rem;
        border-radius: 5px;
        margin-top: 0.5rem;
        font-size: 0.85rem;
        color: #d1d5db;
    }
    
    /* Loading Spinner */
    .spinner {
        border: 3px solid #2d2d2d;
        border-top: 3px solid #3b82f6;
        border-radius: 50%;
        width: 30px;
        height: 30px;
        animation: spin 1s linear infinite;
        display: inline-block;
        margin-right: 0.5rem;
    }
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
</style>
""", unsafe_allow_html=True)

# ================= Initialize Storage =================
@st.cache_resource
def init_storage(data_user_id: str, conv_user_id: str):
    """
    Initialize storage - Users read from admin's data
    
    Args:
        data_user_id: User ID for data (admin_00000000 for all users)
        conv_user_id: User ID for conversation history (unique per user)
    """
    try:
        vector_db = VectorDatabase(data_user_id)
        mongo_storage = MongoStorage(data_user_id)
        
        conv_storage = ConversationStorage(conv_user_id)
        
        feedback_storage = FeedbackStorage(conv_user_id)
        
        retriever = EnhancedHybridRetriever(vector_db, mongo_storage)
        
        vec_stats = vector_db.get_statistics()
        graph = mongo_storage.get_graph()
        
        return {
            'vector_db': vector_db,
            'mongo_storage': mongo_storage,
            'conv_storage': conv_storage,
            'feedback_storage': feedback_storage,
            'retriever': retriever,
            'stats': {
                'vectors': vec_stats['active_vectors'],
                'nodes': len(graph.get('nodes', [])),
                'docs': vec_stats['total_documents']
            }
        }
    except Exception as e:
        st.error(f"âŒ Failed to initialize: {e}")
        return None

storage = init_storage(DATA_USER_ID, user_id)

if not storage:
    st.error("âŒ Failed to initialize chat system")
    st.stop()

retriever = storage['retriever']
conv_storage = storage['conv_storage']
feedback_storage = storage['feedback_storage']
stats = storage['stats']

# ================= Check Data =================
if stats['vectors'] == 0:
    st.warning("âš ï¸ No documents available yet.")
    if role == 'admin':
        if st.button("ğŸ“¤ Go to Upload"):
            st.switch_page("pages/upload.py")
    else:
        st.info("ğŸ’¡ Please contact admin to upload documents.")
    st.stop()

# ================= Header =================
role_badge_class = "badge-admin" if role == "admin" else "badge-user"
role_display = "Admin" if role == "admin" else "User"

st.markdown(f"""
<div class="header-container">
    <div class="header-title">
        ğŸ’¬ Multi-Conversation Chat
        <span class="role-badge {role_badge_class}">{role_display.upper()}</span>
    </div>
</div>
""", unsafe_allow_html=True)

# Show users info 
if role == 'user':
    st.markdown(f"""
    <div class="info-box">
        <strong>ğŸ“š Shared Knowledge Base</strong><br>
        You are chatting with documents uploaded by admin.<br>
        Your conversation history is private and saved separately.
    </div>
    """, unsafe_allow_html=True)

if 'current_conversation_id' not in st.session_state or st.session_state.current_conversation_id is None:
    conversations = conv_storage.list_conversations(limit=1)
    
    if conversations:
        st.session_state.current_conversation_id = conversations[0]['conversation_id']
    else:
        new_conv_id = conv_storage.create_conversation()
        st.session_state.current_conversation_id = new_conv_id

current_conversation_id = st.session_state.current_conversation_id

# ================= Sidebar =================
with st.sidebar:
    st.markdown(f"## ğŸ‘¤ {username}")
    st.markdown(f"**Role**: {role}<br>**ID**: `{user_id}`", unsafe_allow_html=True)
    
    # âœ… Show data source
    if role == 'user':
        st.markdown(f"""
        <div style="background: #1e3a8a; padding: 0.5rem; border-radius: 5px; margin-top: 0.5rem;">
            <small>ğŸ“š Data source: Admin</small>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Conversation List
    st.markdown("### ğŸ’¬ Your Conversations")
    
    if 'creating_new_conv' not in st.session_state:
        st.session_state.creating_new_conv = False
    
    if st.button("â• New Chat", use_container_width=True, type="primary", key="new_chat_btn"):
        if not st.session_state.creating_new_conv:
            st.session_state.creating_new_conv = True
            
            try:
                new_conv_id = conv_storage.create_conversation()
                st.session_state.current_conversation_id = new_conv_id
                st.session_state.messages = []
                
                if 'conv_manager' in st.session_state:
                    del st.session_state.conv_manager
                
                st.session_state.creating_new_conv = False
                st.rerun()
            
            except Exception as e:
                st.error(f"âŒ Failed to create conversation: {e}")
                st.session_state.creating_new_conv = False
    
    # List conversations
    conversations = conv_storage.list_conversations(limit=20)
    current_conv_id = st.session_state.get('current_conversation_id')
    
    for conv in conversations:
        conv_id = conv['conversation_id']
        title = conv['title']
        msg_count = conv.get('message_count', 0)
        updated = conv['updated_at'].strftime("%m/%d %H:%M")
        
        is_active = (conv_id == current_conv_id)
        
        col1, col2 = st.columns([4, 1])
        
        with col1:
            if st.button(
                f"{'ğŸŸ¢' if is_active else 'âšª'} {title}",
                key=f"conv_{conv_id}",
                use_container_width=True,
                type="secondary" if not is_active else "primary"
            ):
                st.session_state.current_conversation_id = conv_id
                
                messages = conv_storage.get_messages(conv_id)
                st.session_state.messages = [
                    {
                        'role': m['role'],
                        'content': m['content'],
                        'metadata': m.get('metadata', {})
                    }
                    for m in messages
                ]
                
                if 'conv_manager' not in st.session_state:
                    st.session_state.conv_manager = ConversationManager(
                        max_history=5,
                        conv_storage=conv_storage,
                        conversation_id=conv_id
                    )
                else:
                    st.session_state.conv_manager.set_conversation(conv_id, conv_storage)
                
                st.rerun()
        
        with col2:
            if st.button("ğŸ—‘ï¸", key=f"del_{conv_id}"):
                conv_storage.delete_conversation(conv_id)
                
                if conv_id == current_conv_id:
                    new_conv_id = conv_storage.create_conversation()
                    st.session_state.current_conversation_id = new_conv_id
                    st.session_state.messages = []
                
                st.rerun()
        
        st.caption(f"{msg_count} msgs Â· {updated}")
    
    st.markdown("---")
    
    # Navigation
    st.markdown("### ğŸ§­ Navigation")
    if role == 'admin':
        if st.button("ğŸ“¤ Upload"):
            st.switch_page("pages/upload.py")
        if st.button("ğŸ•¸ï¸ Graph"):
            st.switch_page("pages/graph.py")
        if st.button("ğŸ“Š Analytics"):  
            st.switch_page("pages/analytics.py")
    else:
        st.info("ğŸ‘ï¸ View-only access")
    
    st.markdown("---")
    
    # Settings
    st.markdown("### âš™ï¸ Settings")
    
    retrieval_mode = st.selectbox(
        "Retrieval Mode",
        options=['auto', 'vector', 'graph', 'hybrid']
    )
    
    top_k = st.slider("Results", 3, 15, 10)
    temperature = st.slider("Temperature", 0.5, 1.0, 0.8, 0.1)
    
    st.markdown("---")
    
    use_history = st.checkbox("Enable history", value=True)
    max_history_turns = st.slider("Max turns", 1, 10, 5)
    show_rewrite = st.checkbox("Show rewrite", value=False)
    
    st.markdown("---")
    
    # Refresh data button
    if st.button("ğŸ”„ Refresh Data", use_container_width=True, help="Reload documents from database"):
        st.cache_resource.clear()
        st.success("âœ… Cache cleared! Reloading...")
        st.rerun()
    
    st.markdown("---")
    
    if st.button("ğŸšª Logout"):
        for k in ['authenticated', 'user_id', 'username', 'role']:
            st.session_state.pop(k, None)
        st.switch_page("login.py")

# Verify conversation_id
if current_conversation_id is None:
    st.error("âŒ Failed to initialize conversation. Please refresh the page.")
    st.stop()

# Initialize conversation manager
if 'conv_manager' not in st.session_state:
    st.session_state.conv_manager = ConversationManager(
        max_history=max_history_turns,
        conv_storage=conv_storage,
        conversation_id=current_conversation_id
    )
else:
    st.session_state.conv_manager.max_history = max_history_turns
    st.session_state.conv_manager.conversation_id = current_conversation_id
    st.session_state.conv_manager.conv_storage = conv_storage

# Load messages
if 'messages' not in st.session_state:
    messages = conv_storage.get_messages(current_conversation_id)
    st.session_state.messages = [
        {
            'role': m['role'],
            'content': m['content'],
            'metadata': m.get('metadata', {})
        }
        for m in messages
    ]

# ================= Show Stats =================
conv_id_display = current_conversation_id[:12] if current_conversation_id else "N/A"

st.markdown(f"""
<div class="context-preview">
    <strong>ğŸ“Š Knowledge Base:</strong>
    ğŸ“„ Docs: {stats['docs']} | 
    ğŸ§® Vectors: {stats['vectors']} | 
    ğŸ•¸ï¸ Nodes: {stats['nodes']} | 
    ğŸ’¬ Conversation: {conv_id_display}...
    {'<br>ğŸ“š <strong>Source: Admin data (shared)</strong>' if role == 'user' else ''}
</div>
""", unsafe_allow_html=True)

# ================= Display Messages =================
for message in st.session_state.messages:
    role_msg = message['role']
    content = message['content']
    
    if role_msg == 'user':
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ğŸ‘¤ You:</strong><br>{content}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message assistant-message">
            <strong>ğŸ¤– Assistant:</strong><br>{content}
        </div>
        """, unsafe_allow_html=True)
        
        if 'metadata' in message:
            meta = message['metadata']
            st.markdown(f"""
            <div style="margin-left: 2rem; margin-top: 0.5rem;">
                <span class="stat-badge badge-chunks">ğŸ“„ {meta.get('num_chunks', 0)}</span>
                <span class="stat-badge badge-entities">ğŸ•¸ï¸ {meta.get('num_entities', 0)}</span>
                <span class="stat-badge badge-time">â±ï¸ {meta.get('retrieval_time_ms', 0)}ms</span>
            </div>
            """, unsafe_allow_html=True)
            
            # Show retrieved chunks
            if 'retrieved_chunks' in message and message['retrieved_chunks']:
                with st.expander(f"ğŸ“„ Retrieved Documents ({len(message['retrieved_chunks'])})", expanded=False):
                    for i, chunk in enumerate(message['retrieved_chunks'], 1):
                        st.markdown(f"**[{i}] {chunk['filename']}** (Score: {chunk['score']:.3f})")
                        st.text(chunk['content'][:300] + "..." if len(chunk['content']) > 300 else chunk['content'])
                        st.markdown("---")
            
            # Show retrieved entities
            if 'retrieved_entities' in message and message['retrieved_entities']:
                with st.expander(f"ğŸ•¸ï¸ Retrieved Entities ({len(message['retrieved_entities'])})", expanded=False):
                    for i, entity in enumerate(message['retrieved_entities'], 1):
                        st.markdown(f"**[{i}] {entity['name']}** ({entity['type']}) - Score: {entity['score']:.3f}")
                        
                        if entity.get('description'):
                            st.markdown(f"*{entity['description'][:200]}...*" if len(entity['description']) > 200 else f"*{entity['description']}*")
                        
                        if entity.get('relationships'):
                            st.markdown("**ğŸ”— Relationships:**")
                            for rel in entity['relationships']:
                                rel_type = rel.get('relationship_type', 'RELATED_TO')
                                target = rel.get('target', 'Unknown')
                                category = rel.get('category', 'general')
                                strength = rel.get('strength', 0.0)
                                st.markdown(f"- **{rel_type}** â†’ {target} [{category}] (strength: {strength:.2f})")
                        
                        st.markdown("---")
        
        #  FEEDBACK & EVALUATION 
        msg_index = st.session_state.messages.index(message)
        
        # Initialize states
        if 'feedbacks' not in st.session_state:
            st.session_state.feedbacks = {}
        
        if 'evaluating' not in st.session_state:
            st.session_state.evaluating = {}
        
        feedback_key = f"{current_conversation_id}_{msg_index}"
        
        existing_feedback = feedback_storage.get_feedback(current_conversation_id, msg_index)
        
        # Check what type of feedback exists
        has_manual_feedback = existing_feedback and existing_feedback.get('rating') is not None
        has_auto_evaluation = existing_feedback and existing_feedback.get('auto_evaluated')
        
        # Show existing feedbacks
        if has_manual_feedback or has_auto_evaluation:
            if has_manual_feedback:
                st.markdown(f"""
                <div class="feedback-submitted">
                    âœ… ÄÃ¡nh giÃ¡ thá»§ cÃ´ng - Rating: {'â­' * existing_feedback['rating']} ({existing_feedback['rating']}/5)
                </div>
                """, unsafe_allow_html=True)
            
            if has_auto_evaluation:
                rel_score = existing_feedback.get('relevancy_score', 0)
                faith_score = existing_feedback.get('faithfulness_score', 0)
                resp_time = existing_feedback.get('response_time_ms', 0)
                
                st.markdown(f"""
                <div class="evaluation-container">
                    <strong>ğŸ“Š ÄÃ¡nh giÃ¡ tá»± Ä‘á»™ng:</strong><br><br>
                    <div class="evaluation-badge badge-relevancy">
                        ğŸ¯ Äá»™ liÃªn quan: <span class="evaluation-score">{rel_score}/5</span>
                    </div>
                    <div class="evaluation-badge badge-faithfulness">
                        âœ… Äá»™ trung thá»±c: <span class="evaluation-score">{faith_score}/5</span>
                    </div>
                    <div class="evaluation-badge badge-response-time">
                        â±ï¸ Thá»i gian: <span class="evaluation-score">{resp_time:.0f}ms</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # Show reasons in expander
                rel_reason = existing_feedback.get('relevancy_reason', '')
                faith_reason = existing_feedback.get('faithfulness_reason', '')
                
                if rel_reason or faith_reason:
                    with st.expander("ğŸ“ Chi tiáº¿t Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng", expanded=False):
                        if rel_reason:
                            st.markdown(f"**ğŸ¯ LÃ½ do Ä‘Ã¡nh giÃ¡ Ä‘á»™ liÃªn quan:**")
                            st.markdown(f'<div class="evaluation-reason">{rel_reason}</div>', unsafe_allow_html=True)
                        if faith_reason:
                            st.markdown(f"**âœ… LÃ½ do Ä‘Ã¡nh giÃ¡ Ä‘á»™ trung thá»±c:**")
                            st.markdown(f'<div class="evaluation-reason">{faith_reason}</div>', unsafe_allow_html=True)
        
        # Show feedback options if not both completed
        if not (has_manual_feedback and has_auto_evaluation):
            with st.expander("ğŸ’¬ ÄÃ¡nh giÃ¡ cÃ¢u tráº£ lá»i nÃ y", expanded=False):
                # Create tabs for manual and auto evaluation
                tab1, tab2 = st.tabs(["â­ ÄÃ¡nh giÃ¡ thá»§ cÃ´ng", "ğŸ¤– ÄÃ¡nh giÃ¡ tá»± Ä‘á»™ng"])
                
                # TAB 1: Manual Feedback
                with tab1:
                    if has_manual_feedback:
                        st.info("âœ… Báº¡n Ä‘Ã£ Ä‘Ã¡nh giÃ¡ thá»§ cÃ´ng cÃ¢u tráº£ lá»i nÃ y rá»“i!")
                    else:
                        st.markdown("**Má»©c Ä‘á»™ hÃ i lÃ²ng:**")
                        
                        col1, col2, col3, col4, col5, col6 = st.columns([1, 1, 1, 1, 1, 3])
                        
                        with col1:
                            if st.button("â­", key=f"star1_{feedback_key}"):
                                st.session_state.feedbacks[feedback_key] = {'rating': 1}
                        with col2:
                            if st.button("â­â­", key=f"star2_{feedback_key}"):
                                st.session_state.feedbacks[feedback_key] = {'rating': 2}
                        with col3:
                            if st.button("â­â­â­", key=f"star3_{feedback_key}"):
                                st.session_state.feedbacks[feedback_key] = {'rating': 3}
                        with col4:
                            if st.button("â­â­â­â­", key=f"star4_{feedback_key}"):
                                st.session_state.feedbacks[feedback_key] = {'rating': 4}
                        with col5:
                            if st.button("â­â­â­â­â­", key=f"star5_{feedback_key}"):
                                st.session_state.feedbacks[feedback_key] = {'rating': 5}
                        
                        current_rating = st.session_state.feedbacks.get(feedback_key, {}).get('rating', 0)
                        
                        if current_rating > 0:
                            st.success(f"ÄÃ£ chá»n: {'â­' * current_rating} ({current_rating}/5)")
                        
                        feedback_text = st.text_area(
                            "Nháº­n xÃ©t (tÃ¹y chá»n):",
                            key=f"feedback_text_{feedback_key}",
                            placeholder="Chia sáº» Ã½ kiáº¿n cá»§a báº¡n vá» cÃ¢u tráº£ lá»i...",
                            height=80
                        )
                        
                        # Submit button
                        if st.button("ğŸ“¤ Gá»­i Ä‘Ã¡nh giÃ¡ thá»§ cÃ´ng", key=f"submit_manual_{feedback_key}", type="primary"):
                            if current_rating > 0:
                                # Save manual feedback
                                success = feedback_storage.save_feedback(
                                    conversation_id=current_conversation_id,
                                    message_index=msg_index,
                                    rating=current_rating,
                                    feedback_text=feedback_text,
                                    # Preserve auto evaluation if exists
                                    relevancy_score=existing_feedback.get('relevancy_score') if existing_feedback else None,
                                    faithfulness_score=existing_feedback.get('faithfulness_score') if existing_feedback else None,
                                    response_time_ms=existing_feedback.get('response_time_ms') if existing_feedback else None,
                                    auto_evaluated=existing_feedback.get('auto_evaluated', False) if existing_feedback else False,
                                    relevancy_reason=existing_feedback.get('relevancy_reason') if existing_feedback else None,
                                    faithfulness_reason=existing_feedback.get('faithfulness_reason') if existing_feedback else None
                                )
                                
                                if success:
                                    st.success("âœ… Cáº£m Æ¡n báº¡n Ä‘Ã£ Ä‘Ã¡nh giÃ¡!")
                                    if feedback_key in st.session_state.feedbacks:
                                        del st.session_state.feedbacks[feedback_key]
                                    st.rerun()
                                else:
                                    st.error("âŒ KhÃ´ng thá»ƒ lÆ°u feedback. Vui lÃ²ng thá»­ láº¡i.")
                            else:
                                st.warning("âš ï¸ Vui lÃ²ng chá»n sá»‘ sao trÆ°á»›c khi gá»­i!")
                
                # TAB 2: Auto Evaluation
                with tab2:
                    if has_auto_evaluation:
                        st.info("âœ… CÃ¢u tráº£ lá»i nÃ y Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng rá»“i!")
                    else:
                        st.markdown("""
                        **Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i theo 3 tiÃªu chÃ­:**
                        - ğŸ¯ **Äá»™ liÃªn quan**: CÃ¢u tráº£ lá»i cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i khÃ´ng
                        - âœ… **Äá»™ trung thá»±c**: CÃ¢u tráº£ lá»i cÃ³ trung thá»±c vá»›i nguá»“n tÃ i liá»‡u khÃ´ng
                        - â±ï¸ **Thá»i gian pháº£n há»“i**: Tá»‘c Ä‘á»™ pháº£n há»“i cá»§a há»‡ thá»‘ng
                        """)
                        
                        # Check if currently evaluating
                        is_evaluating = st.session_state.evaluating.get(feedback_key, False)
                        
                        if is_evaluating:
                            st.markdown("""
                            <div style="text-align: center; padding: 1rem;">
                                <div class="spinner"></div>
                                <span>Äang Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng...</span>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            if st.button("ğŸš€ Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng", key=f"eval_{feedback_key}", type="primary"):
                                st.session_state.evaluating[feedback_key] = True
                                
                                try:
                                    # Get question and answer
                                    question = ""
                                    answer = message['content']
                                    
                                    # Find corresponding user question
                                    for i in range(msg_index - 1, -1, -1):
                                        if st.session_state.messages[i]['role'] == 'user':
                                            question = st.session_state.messages[i]['content']
                                            break
                                    
                                    # Get context from metadata
                                    context_text = ""
                                    if 'retrieved_chunks' in message:
                                        context_text = "\n\n".join([
                                            f"[{chunk['filename']}]: {chunk['content']}"
                                            for chunk in message['retrieved_chunks'][:3]
                                        ])
                                    
                                    # Get response time from metadata
                                    response_time_ms = message.get('metadata', {}).get('response_time_ms', 0)
                                    
                                    # Create evaluator
                                    evaluator = ResponseEvaluator()
                                    
                                    # Run evaluation
                                    with st.spinner("ğŸ” Äang Ä‘Ã¡nh giÃ¡..."):
                                        eval_result = asyncio.run(evaluator.evaluate_response(
                                            question=question,
                                            answer=answer,
                                            context=context_text,
                                            response_time_ms=response_time_ms,
                                            llm_func=call_llm_async
                                        ))
                                    
                                    # Save to database (preserve manual feedback if exists)
                                    success = feedback_storage.save_feedback(
                                        conversation_id=current_conversation_id,
                                        message_index=msg_index,
                                        rating=existing_feedback.get('rating') if existing_feedback else None,
                                        feedback_text=existing_feedback.get('feedback_text') if existing_feedback else None,
                                        relevancy_score=eval_result['relevancy_score'],
                                        faithfulness_score=eval_result['faithfulness_score'],
                                        response_time_ms=eval_result['response_time_ms'],
                                        auto_evaluated=True,
                                        relevancy_reason=eval_result['relevancy_reason'],
                                        faithfulness_reason=eval_result['faithfulness_reason']
                                    )
                                    
                                    if success:
                                        st.success("âœ… ÄÃ¡nh giÃ¡ tá»± Ä‘á»™ng hoÃ n táº¥t!")
                                        st.session_state.evaluating[feedback_key] = False
                                        st.rerun()
                                    else:
                                        st.error("âŒ KhÃ´ng thá»ƒ lÆ°u káº¿t quáº£ Ä‘Ã¡nh giÃ¡")
                                        st.session_state.evaluating[feedback_key] = False
                                
                                except Exception as e:
                                    st.error(f"âŒ Lá»—i Ä‘Ã¡nh giÃ¡: {e}")
                                    st.session_state.evaluating[feedback_key] = False


# ================= Chat Input =================
st.markdown("---")

user_query = st.chat_input("Ask me anything...")

if user_query:
    st.session_state.messages.append({
        'role': 'user',
        'content': user_query
    })
    
    st.markdown(f"""
    <div class="chat-message user-message">
        <strong>ğŸ‘¤ You:</strong><br>{user_query}
    </div>
    """, unsafe_allow_html=True)
    
    with st.spinner("ğŸ¤” Thinking..."):
        try:
            # Start tracking response time
            start_time = time.time()
            
            # Query rewriting
            original_query = user_query
            if use_history:
                user_query = st.session_state.conv_manager.rewrite_query(
                    user_query,
                    llm_func=call_llm_async
                )
                
                if show_rewrite and user_query != original_query:
                    st.info(f"ğŸ”„ Rewritten: {user_query}")
            
            # Retrieval (from admin's data)
            force_mode = None if retrieval_mode == 'auto' else retrieval_mode
            context = retriever.retrieve(
                query=user_query,
                force_mode=force_mode,
                top_k=top_k
            )
            
            # Build prompt
            messages_for_llm = []
            
            system_prompt = """Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  thÃ¢n thiá»‡n, chuyÃªn há»— trá»£ ngÆ°á»i dÃ¹ng tÃ¬m kiáº¿m thÃ´ng tin tá»« tÃ i liá»‡u vÃ  Ä‘á»“ thá»‹ tri thá»©c.

ğŸ¯ PHONG CÃCH GIAO TIáº¾P:
- Tráº£ lá»i tá»± nhiÃªn, mÆ°á»£t mÃ  nhÆ° Ä‘ang trÃ² chuyá»‡n
- Sá»­ dá»¥ng ngÃ´n ngá»¯ Ä‘Æ¡n giáº£n, dá»… hiá»ƒu, trÃ¡nh thuáº­t ngá»¯ ká»¹ thuáº­t khÃ´ng cáº§n thiáº¿t
- Thá»ƒ hiá»‡n sá»± nhiá»‡t tÃ¬nh vÃ  quan tÃ¢m Ä‘áº¿n cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
- CÃ³ thá»ƒ sá»­ dá»¥ng emoji má»™t cÃ¡ch tinh táº¿ Ä‘á»ƒ táº¡o sá»± gáº§n gÅ©i (khÃ´ng láº¡m dá»¥ng)

ğŸ“‹ NGUYÃŠN Táº®C TRáº¢ Lá»œI:
1. **XÃ¡c Ä‘á»‹nh Ä‘Ãºng Ä‘á»‘i tÆ°á»£ng**: Äá»c ká»¹ cÃ¢u há»i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c entity/ngÆ°á»i Ä‘Æ°á»£c há»i
2. **Táº­p trung vÃ o entity Ä‘Ã³**: Chá»‰ tráº£ lá»i vá» entity Ä‘Æ°á»£c há»i, khÃ´ng tráº£ lá»i vá» cÃ¡c entity khÃ¡c
3. **Sá»­ dá»¥ng context phÃ¹ há»£p**:
   - CÃ¢u há»i vá» má»‘i quan há»‡ â†’ DÃ¹ng LOCAL CONTEXT (Knowledge Graph)
   - CÃ¢u há»i vá» thÃ´ng tin tÃ i liá»‡u â†’ DÃ¹ng GLOBAL CONTEXT (Documents) vÃ  trÃ­ch dáº«n [1], [2]
4. **Kiá»ƒm tra trÆ°á»›c khi tráº£ lá»i**: Äáº£m báº£o cÃ¢u tráº£ lá»i Ä‘Ãºng vá» entity Ä‘Æ°á»£c há»i

ğŸ’¡ Cáº¤U TRÃšC CÃ‚U TRáº¢ Lá»œI Tá»° NHIÃŠN:
- Báº¯t Ä‘áº§u báº±ng cÃ¢u má»Ÿ Ä‘áº§u ngáº¯n gá»n, thÃ¢n thiá»‡n
- TrÃ¬nh bÃ y thÃ´ng tin theo luá»“ng logic, dá»… theo dÃµi
- Sá»­ dá»¥ng cÃ¢u chuyá»ƒn tiáº¿p mÆ°á»£t mÃ  giá»¯a cÃ¡c Ã½
- Káº¿t thÃºc báº±ng tÃ³m táº¯t hoáº·c gá»£i Ã½ náº¿u phÃ¹ há»£p

âŒ TRÃNH:
- Liá»‡t kÃª thÃ´ng tin theo dáº¡ng bullet points trá»« khi thá»±c sá»± cáº§n thiáº¿t
- Sá»­ dá»¥ng cáº¥u trÃºc cÃ¢u mÃ¡y mÃ³c nhÆ° "Theo tÃ i liá»‡u...", "Dá»±a vÃ o context..."
- Láº·p láº¡i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng trong cÃ¢u tráº£ lá»i
- Tráº£ lá»i quÃ¡ dÃ i dÃ²ng hoáº·c quÃ¡ ngáº¯n gá»n

âœ… VÃ Dá»¤:
CÃ¢u há»i: "VÅ© HoÃ ng Hiá»‡p cÃ³ quan há»‡ vá»›i nhá»¯ng ai?"
âŒ Sai: "Dá»±a vÃ o knowledge graph, tÃ´i tháº¥y Nguyá»…n VÄƒn A cÃ³ cÃ¡c má»‘i quan há»‡ sau..."
âœ… ÄÃºng: "VÅ© HoÃ ng Hiá»‡p cÃ³ má»‘i quan há»‡ vá»›i nhiá»u ngÆ°á»i. Anh áº¥y lÃ  Ä‘á»“ng nghiá»‡p cá»§a Nguyá»…n VÄƒn A, cÃ¹ng lÃ m viá»‡c táº¡i cÃ´ng ty XYZ. NgoÃ i ra, anh cÃ²n cÃ³ má»‘i quan há»‡ há»£p tÃ¡c vá»›i..."

HÃ£y nhá»›: Tráº£ lá»i chÃ­nh xÃ¡c nhÆ°ng váº«n giá»¯ Ä‘Æ°á»£c sá»± tá»± nhiÃªn vÃ  thÃ¢n thiá»‡n!"""

            if use_history:
                history_context = st.session_state.conv_manager.get_context_for_llm()
                messages_for_llm.extend(history_context)
            
            user_prompt = f"""
{context.formatted_text}

Question: {user_query}
"""
            messages_for_llm.append({"role": "user", "content": user_prompt})
            
            # Prepare prompt for streaming
            if use_history and len(messages_for_llm) > 1:
                full_prompt = "\n\n".join([
                    f"{'User' if m['role'] == 'user' else 'Assistant'}: {m['content']}"
                    for m in messages_for_llm[:-1]
                ]) + f"\n\nUser: {user_prompt}"
            else:
                full_prompt = user_prompt
            
            # Stream LLM response
            response_placeholder = st.empty()
            response_container = [""]  # Use list to avoid nonlocal binding issues
            
            try:
                # Create async generator for streaming
                async def stream_response():
                    async for chunk in call_llm_stream(
                        prompt=full_prompt,
                        system_prompt=system_prompt,
                        temperature=temperature,
                        max_tokens=2000
                    ):
                        yield chunk
                
                # Display streaming response
                async def collect_response():
                    async for chunk in stream_response():
                        response_container[0] += chunk
                        # Update display with markdown formatting
                        response_placeholder.markdown(f"""
                        <div class="chat-message assistant-message">
                            <strong>ğŸ¤– Assistant:</strong><br>{response_container[0]}
                        </div>
                        """, unsafe_allow_html=True)
                
                # Run streaming
                asyncio.run(collect_response())
                response = response_container[0]
                
            except Exception as e:
                st.error(f"âŒ LLM call failed: {e}")
                raise
            
            # Calculate response time
            end_time = time.time()
            response_time_ms = (end_time - start_time) * 1000
            
            # Save to MongoDB
            if use_history:
                st.session_state.conv_manager.add_message('user', original_query, save_to_db=True)
                st.session_state.conv_manager.add_message('assistant', response, save_to_db=True)
            
            # Add response time to metadata
            metadata_with_time = context.metadata.copy()
            metadata_with_time['response_time_ms'] = response_time_ms
            
            # Save to UI with full context 
            assistant_message = {
                'role': 'assistant',
                'content': response,
                'metadata': metadata_with_time,
                'retrieved_chunks': [
                    {
                        'content': chunk.content,
                        'filename': chunk.filename,
                        'score': chunk.score,
                        'chunk_id': chunk.chunk_id
                    }
                    for chunk in context.global_chunks[:top_k]  # Sá»­ dá»¥ng giÃ¡ trá»‹ tá»« slider
                ],
                'retrieved_entities': [
                    {
                        'name': entity.entity_name,
                        'type': entity.entity_type,
                        'description': entity.description,
                        'relationships': entity.relationships[:3],  
                        'score': entity.score
                    }
                    for entity in context.local_entities[:top_k]  
                ]
            }
            st.session_state.messages.append(assistant_message)
            
            # Auto-generate title
            if len(st.session_state.messages) == 2:
                conv_storage.auto_generate_title(
                    current_conversation_id,
                    llm_func=call_llm_async
                )
            
            st.rerun()
        
        except Exception as e:
            st.error(f"âŒ Error: {e}")

# ================= Footer =================
st.markdown("---")
footer_text = "ğŸ’¬ Multi-Conversation Chat â€“ mini-lightrag v2.2"
if role == 'user':
    footer_text += " (Shared Knowledge Base)"

st.markdown(f"""
<div style="text-align: center; color: #6b7280; font-size: 0.9rem;">
    <p>{footer_text}</p>
</div>
""", unsafe_allow_html=True)