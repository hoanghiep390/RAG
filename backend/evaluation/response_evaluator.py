# backend/evaluation/response_evaluator.py
"""
Há»‡ Thá»‘ng ÄÃ¡nh GiÃ¡ Tá»± Äá»™ng (LLM-as-a-Judge)
ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i theo 3 tiÃªu chÃ­: Relevancy, Faithfulness, Response Time
"""
from typing import Dict, Optional, Callable
import asyncio
import json
import logging
import re

logger = logging.getLogger(__name__)

class ResponseEvaluator:
    """
    LLM-as-a-Judge Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i
    
    Sá»­ dá»¥ng LLM Ä‘á»ƒ Ä‘Ã¡nh giÃ¡:
    1. Relevancy: Äá»™ liÃªn quan giá»¯a cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i
    2. Faithfulness: Äá»™ trung thá»±c cá»§a cÃ¢u tráº£ lá»i so vá»›i nguá»“n tÃ i liá»‡u
    """
    
    def __init__(self):
        """Khá»Ÿi táº¡o evaluator"""
        pass
    
    async def evaluate_relevancy(
        self,
        question: str,
        answer: str,
        llm_func: Callable
    ) -> Dict:
        """
        ÄÃ¡nh giÃ¡ Ä‘á»™ liÃªn quan giá»¯a cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i
        
        Args:
            question: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
            answer: CÃ¢u tráº£ lá»i cá»§a chatbot
            llm_func: HÃ m gá»i LLM (async)
        
        Returns:
            Dict vá»›i 'score' (1-5) vÃ  'reason' (lÃ½ do)
        """
        try:
            prompt = f"""Báº¡n lÃ  má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i AI.

Nhiá»‡m vá»¥: ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ liÃªn quan giá»¯a cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i.

CÃ¢u há»i: {question}

CÃ¢u tráº£ lá»i: {answer}

TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ (1-5):
1 = HoÃ n toÃ n khÃ´ng liÃªn quan - CÃ¢u tráº£ lá»i khÃ´ng Ä‘á» cáº­p Ä‘áº¿n ná»™i dung cÃ¢u há»i
2 = Ãt liÃªn quan - CÃ¢u tráº£ lá»i chá»‰ Ä‘á» cáº­p má»™t pháº§n nhá» cá»§a cÃ¢u há»i
3 = Trung bÃ¬nh - CÃ¢u tráº£ lá»i liÃªn quan nhÆ°ng thiáº¿u chi tiáº¿t hoáº·c khÃ´ng trá»±c tiáº¿p
4 = Ráº¥t liÃªn quan - CÃ¢u tráº£ lá»i trá»±c tiáº¿p giáº£i quyáº¿t cÃ¢u há»i vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
5 = HoÃ n háº£o - CÃ¢u tráº£ lá»i trá»±c tiáº¿p, Ä‘áº§y Ä‘á»§ vÃ  chÃ­nh xÃ¡c giáº£i quyáº¿t cÃ¢u há»i

HÃ£y tráº£ vá» JSON vá»›i format sau (KHÃ”NG thÃªm markdown code block):
{{"score": <1-5>, "reason": "<giáº£i thÃ­ch ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t>"}}"""

            # Gá»i LLM
            result = await llm_func(
                prompt,
                system_prompt="Báº¡n lÃ  má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡. Chá»‰ tráº£ vá» JSON, khÃ´ng thÃªm text khÃ¡c.",
                temperature=0.0,
                max_tokens=300
            )
            
            # Parse JSON tá»« response
            parsed = self._parse_json_response(result)
            
            # Validate
            if not isinstance(parsed.get('score'), int) or not (1 <= parsed['score'] <= 5):
                logger.warning(f"Invalid relevancy score: {parsed.get('score')}, defaulting to 3")
                parsed['score'] = 3
            
            if not parsed.get('reason'):
                parsed['reason'] = "KhÃ´ng cÃ³ lÃ½ do cá»¥ thá»ƒ"
            
            logger.info(f"âœ… Relevancy evaluated: {parsed['score']}/5")
            return parsed
        
        except Exception as e:
            logger.error(f"âŒ Lá»—i Ä‘Ã¡nh giÃ¡ relevancy: {e}")
            return {
                'score': 3,
                'reason': f"Lá»—i Ä‘Ã¡nh giÃ¡: {str(e)}"
            }
    
    async def evaluate_faithfulness(
        self,
        answer: str,
        context: str,
        llm_func: Callable
    ) -> Dict:
        """
        ÄÃ¡nh giÃ¡ Ä‘á»™ trung thá»±c cá»§a cÃ¢u tráº£ lá»i so vá»›i nguá»“n tÃ i liá»‡u
        
        Args:
            answer: CÃ¢u tráº£ lá»i cá»§a chatbot
            context: Nguá»“n tÃ i liá»‡u Ä‘Æ°á»£c trÃ­ch dáº«n (retrieved context)
            llm_func: HÃ m gá»i LLM (async)
        
        Returns:
            Dict vá»›i 'score' (1-5) vÃ  'reason' (lÃ½ do)
        """
        try:
            # Truncate context náº¿u quÃ¡ dÃ i
            max_context_length = 2000
            if len(context) > max_context_length:
                context = context[:max_context_length] + "..."
            
            prompt = f"""Báº¡n lÃ  má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡ Ä‘á»™ trung thá»±c cá»§a thÃ´ng tin.

Nhiá»‡m vá»¥: ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ trung thá»±c cá»§a cÃ¢u tráº£ lá»i so vá»›i nguá»“n tÃ i liá»‡u.

Nguá»“n tÃ i liá»‡u (Context):
{context}

CÃ¢u tráº£ lá»i:
{answer}

TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ (1-5):
1 = Sai lá»‡ch hoÃ n toÃ n - CÃ¢u tráº£ lá»i mÃ¢u thuáº«n vá»›i nguá»“n tÃ i liá»‡u
2 = Ãt trung thá»±c - CÃ¢u tráº£ lá»i cÃ³ nhiá»u thÃ´ng tin khÃ´ng cÃ³ trong nguá»“n
3 = Trung bÃ¬nh - CÃ¢u tráº£ lá»i má»™t pháº§n dá»±a trÃªn nguá»“n, má»™t pháº§n suy luáº­n
4 = Ráº¥t trung thá»±c - CÃ¢u tráº£ lá»i chá»§ yáº¿u dá»±a trÃªn nguá»“n tÃ i liá»‡u
5 = HoÃ n toÃ n trung thá»±c - Má»i thÃ´ng tin Ä‘á»u cÃ³ trong nguá»“n tÃ i liá»‡u

HÃ£y tráº£ vá» JSON vá»›i format sau (KHÃ”NG thÃªm markdown code block):
{{"score": <1-5>, "reason": "<giáº£i thÃ­ch ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t>"}}"""

            # Gá»i LLM
            result = await llm_func(
                prompt,
                system_prompt="Báº¡n lÃ  má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡. Chá»‰ tráº£ vá» JSON, khÃ´ng thÃªm text khÃ¡c.",
                temperature=0.0,
                max_tokens=300
            )
            
            # Parse JSON tá»« response
            parsed = self._parse_json_response(result)
            
            # Validate
            if not isinstance(parsed.get('score'), int) or not (1 <= parsed['score'] <= 5):
                logger.warning(f"Invalid faithfulness score: {parsed.get('score')}, defaulting to 3")
                parsed['score'] = 3
            
            if not parsed.get('reason'):
                parsed['reason'] = "KhÃ´ng cÃ³ lÃ½ do cá»¥ thá»ƒ"
            
            logger.info(f"âœ… Faithfulness evaluated: {parsed['score']}/5")
            return parsed
        
        except Exception as e:
            logger.error(f"âŒ Lá»—i Ä‘Ã¡nh giÃ¡ faithfulness: {e}")
            return {
                'score': 3,
                'reason': f"Lá»—i Ä‘Ã¡nh giÃ¡: {str(e)}"
            }
    
    async def evaluate_response(
        self,
        question: str,
        answer: str,
        context: str,
        response_time_ms: float,
        llm_func: Callable
    ) -> Dict:
        """
        ÄÃ¡nh giÃ¡ tá»•ng há»£p cÃ¢u tráº£ lá»i theo 3 tiÃªu chÃ­
        
        Args:
            question: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
            answer: CÃ¢u tráº£ lá»i cá»§a chatbot
            context: Nguá»“n tÃ i liá»‡u Ä‘Æ°á»£c trÃ­ch dáº«n
            response_time_ms: Thá»i gian pháº£n há»“i (milliseconds)
            llm_func: HÃ m gá»i LLM (async)
        
        Returns:
            Dict vá»›i cÃ¡c tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡
        """
        try:
            logger.info("ğŸ” Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng...")
            
            # ÄÃ¡nh giÃ¡ song song Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian
            relevancy_task = self.evaluate_relevancy(question, answer, llm_func)
            faithfulness_task = self.evaluate_faithfulness(answer, context, llm_func)
            
            relevancy, faithfulness = await asyncio.gather(
                relevancy_task,
                faithfulness_task
            )
            
            result = {
                'relevancy_score': relevancy['score'],
                'relevancy_reason': relevancy['reason'],
                'faithfulness_score': faithfulness['score'],
                'faithfulness_reason': faithfulness['reason'],
                'response_time_ms': round(response_time_ms, 2),
                'auto_evaluated': True
            }
            
            logger.info(f"âœ… ÄÃ¡nh giÃ¡ hoÃ n táº¥t: R={result['relevancy_score']}/5, F={result['faithfulness_score']}/5, T={result['response_time_ms']}ms")
            return result
        
        except Exception as e:
            logger.error(f"âŒ Lá»—i Ä‘Ã¡nh giÃ¡ tá»•ng há»£p: {e}")
            return {
                'relevancy_score': 3,
                'relevancy_reason': f"Lá»—i: {str(e)}",
                'faithfulness_score': 3,
                'faithfulness_reason': f"Lá»—i: {str(e)}",
                'response_time_ms': round(response_time_ms, 2),
                'auto_evaluated': True
            }
    
    def _parse_json_response(self, response: str) -> Dict:
        """
        Parse JSON tá»« LLM response (xá»­ lÃ½ cáº£ markdown code blocks)
        
        Args:
            response: Response tá»« LLM
        
        Returns:
            Parsed JSON dict
        """
        try:
            # Loáº¡i bá» markdown code blocks náº¿u cÃ³
            response = response.strip()
            
            # TÃ¬m JSON trong markdown code block
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                response = json_match.group(1)
            
            # TÃ¬m JSON object Ä‘áº§u tiÃªn
            json_match = re.search(r'\{.*?\}', response, re.DOTALL)
            if json_match:
                response = json_match.group(0)
            
            # Parse JSON
            return json.loads(response)
        
        except Exception as e:
            logger.error(f"âŒ KhÃ´ng thá»ƒ parse JSON: {e}, response: {response[:200]}")
            # Fallback: tráº£ vá» default
            return {
                'score': 3,
                'reason': "KhÃ´ng thá»ƒ parse káº¿t quáº£ Ä‘Ã¡nh giÃ¡"
            }


# ============================================
# UTILITY FUNCTIONS
# ============================================

def create_evaluator() -> ResponseEvaluator:
    """
    Factory function
    
    Usage:
        evaluator = create_evaluator()
    """
    return ResponseEvaluator()
